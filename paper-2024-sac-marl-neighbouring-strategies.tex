\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables


% Copyright
%\setcopyright{none}
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{xx.xxx/xxx_x}

% ISBN
\acmISBN{979-8-4007-0629-5/25/03}

%Conference
\acmConference[SAC'25]{ACM SAC Conference}{March 31 â€“April 4, 2025}{Sicily, Italy}
\acmYear{2025}
\copyrightyear{2025}


\acmArticle{4}
\acmPrice{15.00}

% These commands are optional
%\acmBooktitle{Transactions of the ACM Woodstock conference}
%\editor{Jennifer B. Sartor}
%\editor{Theo D'Hondt}
%\editor{Wolfgang De Meuter}


\begin{document}
\title{Neighbor-Based Decentralized Training Strategies for Multi-Agent Reinforcement Learning}
\titlenote{Produces the permission block, and
  copyright information}
\subtitle{Full Paper}
\subtitlenote{The full version of the author's guide is available as
  \texttt{acmart.pdf} document}
  
\renewcommand{\shorttitle}{SIG Proceedings Paper in LaTeX Format}


\author{Ben Trovato}
\authornote{Dr.~Trovato insisted his name be first.}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \streetaddress{P.O. Box 1212}
  \city{Dublin} 
  \state{Ohio} 
  \country{USA}
  \postcode{43017-6221}  
}
\email{trovato@corporation.com}

\author{G.K.M. Tobin}
\authornote{The secretary disavows any knowledge of this author's actions.}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \streetaddress{P.O. Box 1212}
  \city{Dublin} 
  \state{Ohio} 
  \country{USA}
  \postcode{43017-6221}  
}
\email{webmaster@marysville-ohio.com}

\author{Lars Th{\o}rv{\"a}ld}
\authornote{This author is the
  one who did all the really hard work.}
\affiliation{%
  \institution{The Th{\o}rv{\"a}ld Group}
  \streetaddress{1 Th{\o}rv{\"a}ld Circle}
  \city{Hekla} 
  \country{Iceland}}
\email{larst@affiliation.org}

\author{Valerie B\'eranger}
\affiliation{%
  \institution{Inria Paris-Rocquencourt}
  \city{Rocquencourt}
  \country{France}
}
\author{Aparna Patel} 
\affiliation{%
 \institution{Rajiv Gandhi University}
 \streetaddress{Rono-Hills}
 \city{Doimukh} 
 \state{Arunachal Pradesh}
 \country{India}}
\author{Huifen Chan}
\affiliation{%
  \institution{Tsinghua University}
  \streetaddress{30 Shuangqing Rd}
  \city{Haidian Qu} 
  \state{Beijing Shi}
  \country{China}
}

\author{Charles Palmer}
\affiliation{%
  \institution{Palmer Research Laboratories}
  \streetaddress{8600 Datapoint Drive}
  \city{San Antonio}
  \state{Texas} 
  \country{USA}
  \postcode{78229}}  
\email{cpalmer@prl.com}



% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{B. Trovato et al.}


\begin{abstract}
  Multi-Agent Reinforcement Learning (MARL) is gaining popularity as a powerful framework for training agents to collaborate and compete in complex environments. However, MARL introduces unique challenges, such as non-stationarity and partial observability, that complicate the training process.  
  While centralized training methods can address some of these challenges, they often face scalability limitations as the number of agents grows. This paper investigates the effectiveness of various neighbor-based decentralized training strategies as a viable alternative to centralized training. We evaluate Experience Sharing, Nearest Neighboring Averaging, and Nearest Neighboring Consensus methods in a custom multi-agent environment and compare their performance against centralized training. Our results show that neighbor-based methods can achieve comparable performance to centralized training while offering improved scalability and communication efficiency. 
  We discuss the trade-offs between these methods and provide insights into their applicability in different scenarios.
  %% More -- add the fact that this make it possible to train agents in a decentralized manner, which is more realistic and scalable than centralized training.
\end{abstract}
%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


\keywords{ACM proceedings, \LaTeX, text tagging}
\maketitle

\section{Introduction}
\begin{itemize}
\item Highlight the growing importance of MARL and its applications.
\item Discuss the challenges of MARL: non-stationarity, scalability, partial observability, and credit assignment.
\item Introduce the limitations of centralized training in MARL, specifically scalability issues and online learning challenges.
\item Present the motivation for exploring neighbor-based decentralized training strategies as a potential solution.
\item State the main objectives of the paper: to evaluate and compare the effectiveness of different neighbor-based methods and analyze their trade-offs.
\end{itemize}

\section{Background}
\begin{itemize}
\item Introduce Multi-Agent Reinforcement Learning (MARL) and its specific challenges.
\item Provide a formalization (networked agents?) and explain the key concepts: joint action space, shared reward, partial observability, and credit assignment.
\item Explain different MARL training schemes: centralized training (CTCE, CTDE), distributed training (DTDE).
\end{itemize}

\section{Neighboring-Based Distributed Learning Strategies}
\begin{itemize}
\item Provide a detailed explanation of each neighbor-based method:
\begin{itemize}
\item \textbf{Independent learners:} Emphasize its simplicity and scalability but highlight its vulnerability to non-stationarity.
\item \textbf{NN-Averaging:} Describe the weight averaging process, discuss the influence of neighbor selection and averaging frequency, and mention weighted averaging variations.
\item \textbf{NN-Consensus:} Explain the selection of the best-performing network and its potential benefits and drawbacks.
\item \textbf{Experience Sharing:} Detail how agents share experiences, discuss asynchronous vs. synchronous sharing, and highlight its advantages in sparse interaction environments.
\end{itemize}
\end{itemize}

\section{Experimental Setup}
\begin{itemize}
\item Introduce the custom "collect the items" multi-agent environment:
\begin{itemize}
\item Describe the environment's dynamics, agent goals, and challenges.
\item Specify the action space (continuous and discrete) and observation space design.
\item Explain the reward structure, emphasizing the components that encourage cooperation.
\end{itemize}
\item Detail the implementation framework (Gymnasium, RLlib, PyTorch).
\item Specify the chosen RL algorithm (DQN) and its hyperparameter configuration.
\item Define the evaluation metrics: average episode length and average reward.
\end{itemize}

\section{Results and Evaluation}
\begin{itemize}
\item \textbf{Performance comparison:}
\begin{itemize}
\item Present the results of each distributed strategy against the centralized training baseline.
\item Use graphs and statistical analysis to compare the average episode length and average reward.
\item Highlight which neighbor-based methods perform comparably to centralized training.
\end{itemize}
\item \textbf{Scalability analysis:}
\begin{itemize}
\item Describe how the experiments were modified to assess scalability (increasing agents, spawn area).
\item Show how each method scales with the increasing complexity, using appropriate visualizations.
\item Discuss the implications of using pre-trained models with a larger number of agents.
\end{itemize}
\item \textbf{Communication overhead analysis:}
\begin{itemize}
\item Quantify the amount of information exchange for each strategy.
\item Compare the communication overhead across different neighborhood sizes, possibly using graphs.
\item Discuss the trade-offs between performance and communication efficiency.
\item Mention potential techniques for reducing communication overhead.
\end{itemize}
\end{itemize}

\section{Conclusion}
\begin{itemize}
\item Summarize the key findings of the paper.
\item Emphasize the viability of neighbor-based methods as alternatives to centralized training in MARL.
\item Discuss the trade-offs observed in terms of performance, scalability, and communication overhead.
\item Suggest potential directions for future research, such as exploring hybrid approaches or more advanced communication protocols.
\end{itemize}


\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-bibliography} 

\end{document}
